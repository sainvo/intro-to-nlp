{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Primer\n",
    "\n",
    "* Machine learning is a group of algorithms which adapt their behavior based on observations\n",
    "    * Learns to perform a specific task without using explicit instructions\n",
    "* Objective is to perform better on the given task after observing examples\n",
    "\n",
    "### Example task: Given a fruit, recognize whether it's an apple &#127822; or a banana &#127820;.\n",
    "\n",
    "* **Rule-based approach:** Write instructions how to solve the task, i.e. how to recognize apples &#127822; and bananas &#127820;. \n",
    "    * If it's red, it must be an apple &#127822;\n",
    "    * If it's thin and quite long, it's a banana &#127820;\n",
    "    * If its shape is roundish, it's an apple &#127822; \n",
    "    * If it has brown texture on top of yellow background, it's a banana &#127820;\n",
    "    * Otherwise I'm not sure, but lets guess it's an apple &#127822;\n",
    "    \n",
    "    \n",
    "* **Machine learning approach:** Give a bag of apples &#127822; and bananas &#127820; each labeled with the correct class (&#127822;/&#127820;), and let the machine to figure out the usual patterns how apples &#127822; and bananas &#127820; looks like and how to differentiate those two\n",
    "\n",
    "### Motivation\n",
    "\n",
    "* Many real-life scenarios are too complicated to define as a set rules\n",
    "* Natural language has certain predefined structures and rules (grammar), but also exceptions, and exceptions of exception\n",
    "    * No formal requirements to follow the rules\n",
    "    * Not all rules are known\n",
    "* Almost all modern NLP methods are based on machine learning\n",
    "    * Neural networks is the hot topic currently\n",
    "\n",
    "### Machine Learning in a nutshell (classification)\n",
    "\n",
    "* Dataset: Examples describing the task you are trying to solve\n",
    "    * The dataset must reflect the task, and represent the real-life situation well\n",
    "    * Can you predict tomorrow's weather, if you know today's menu?\n",
    "    * If you want to model daily weather conditions, you need to include measurements throughout the year, not only summer time\n",
    "\n",
    "* Find a hypothesis (mathematical function) that explains patterns in your data as well as possible\n",
    "    * Start from random guessing\n",
    "    * Let the machine to see one example (without the ground truth label)\n",
    "    * Ask it to predict (or guess) the correct label\n",
    "    * Punish/reward (update the hypothesis)\n",
    "    * Continue until satisfied\n",
    "    \n",
    "* Now we have the function (trained model), which is able to guess the ground truth label for a given example\n",
    "    \n",
    "    \n",
    "### Supervised / Unsupervised Learning\n",
    "\n",
    "* **Supervised:** Each example has a predefined label, which is known (the ground truth)\n",
    "* The set of possible labels is fixed\n",
    "* Classification, Regression\n",
    "\n",
    "\n",
    "* **Unsupervised:** Bunch of examples representing the situation, but the ground truths are not known\n",
    "* The set of groups/labels not known\n",
    "* Clustering\n",
    "    * Divide the data into X groups, but we do not know beforehand what kind of groups there should be\n",
    "    * Clustering can be 'controlled' by how the examples are described to the algorithm (feature representation)\n",
    "\n",
    "## Classification\n",
    "\n",
    "* For a given example, predict one (or more) of the pre-defined classes\n",
    "* E.g. *Divide a bag of fruits into apples &#127822; and bananas &#127820;*\n",
    "    * For each fruit, guess whether it's an apple &#127822; or banana &#127820;\n",
    "* Supervised learning: Each example in the training data includes a ground truth label\n",
    "\n",
    "### Data representation\n",
    "\n",
    "* Each example must be somehow described to the machine\n",
    "    * Fruits: Color, size, shape, taste\n",
    "    * Picture: Pixel values\n",
    "    * Text: which words/characters the text includes\n",
    "    \n",
    "&#8594; Features\n",
    "* Each example in our dataset can be represented with a set of these features (feature vector)\n",
    "* If we have only two different features (e.g. size and color), we can easily visualize the data in a 2D plot\n",
    "    * When we have hundreds of features, meaningful visualization is very difficult\n",
    "    \n",
    "### Training\n",
    "\n",
    "* Try to find a hypothesis that explains your data\n",
    "* In classification: if you have two classes, and two distinct features (2D plot), try ro find a line that separates these two classes\n",
    "    * With more classes and more features, the function is more complicated...\n",
    "    \n",
    "* How?\n",
    "* Start from a random hypothesis (line), say all points above the line are apples &#127822;, all below are bananas &#127820;\n",
    "* Take the first example from your dataset, and based on the features you can 'draw' the point to the plot\n",
    "* Compare the hypothesis to the ground truth, if correct reward or do nothing, if wrong punish\n",
    "    * Punish basically means a method to update our hypothesis\n",
    "    * Cost function: How wrong our current hypothesis was, and how radically it should be updated\n",
    "* Update the hypothesis (parameters in the line)\n",
    "* Continue until hypothesis is as good as possible\n",
    "    * not always perfect, sometimes a simple line cannot separate two groups   \n",
    "\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "* It's possible to generate a hypothesis which explains any kind of data perfectly\n",
    "* It can learn to remember the training data exactly\n",
    "* Does not generalize at all!\n",
    "    * Does not create reasonable predictions for new, previously unseen data points\n",
    "* Complexity of the hypothesis must be controlled (regularization)\n",
    "\n",
    "![overfitting.png](figs/overfitting.png)\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "* How good is the trained model? How many mistakes (wrong classifications) it does on average?\n",
    "* Ability to remember your training data does not tell how good your model is\n",
    "    * Computers have almost unlimited memory\n",
    "* You need to test how well your hypothesis (trained model) generalizes to new, unseen data examples\n",
    "* Separate training, development and test data needed!!!\n",
    "* **Training data:** Used for training the model\n",
    "* **Development data:** Used for testing different model parameters, for example level of regularization needed\n",
    "* **Test data:** Never touched during training / model development, used for evaluating the final model\n",
    "\n",
    "\n",
    "Evaluation metric:\n",
    "\n",
    "* Accuracy: Out of all test examples, how many were classified correctly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
